{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data:  airline sentiment kaggle dataset \n",
    "## Purpose: train model solely using the text to classify a tweet as positive neutral negative sentiment. Report findings with classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"./database.sqlite\")\n",
    "df = pd.read_sql_query(\"SELECT * from Tweets\", con)\n",
    "\n",
    "# verify that result of SQL query is stored in the dataframe\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567588278875213824</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue's new CEO seeks the right balance to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-16 23:36:05 -0800</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567590027375702016</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nesi_1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ï¿½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-16 23:43:02 -0800</td>\n",
       "      <td>undecided</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  567588278875213824           neutral                           1.0   \n",
       "1  567590027375702016          negative                           1.0   \n",
       "\n",
       "  negativereason  negativereason_confidence airline airline_sentiment_gold  \\\n",
       "0            NaN                        NaN   Delta                    NaN   \n",
       "1     Can't Tell                     0.6503   Delta                    NaN   \n",
       "\n",
       "          name negativereason_gold  retweet_count  \\\n",
       "0  JetBlueNews                 NaN              0   \n",
       "1    nesi_1992                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @JetBlue's new CEO seeks the right balance to ...         NaN   \n",
       "1  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ï¿½...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-16 23:36:05 -0800            USA                      Sydney  \n",
       "1  2015-02-16 23:43:02 -0800      undecided  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('',np.nan, inplace = True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean text of punctuation, url, stopwords    \n",
    "\n",
    "#stops = set(stopwords.words(\"english\")) \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.encode('utf-8')\n",
    "    text = re.sub('https(.)*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub('http','', text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    return text\n",
    "df.text = df.text.apply(lambda val: clean_text(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     JetBlue s new CEO seeks the right balance to ...\n",
       "1     JetBlue is REALLY getting on my nerves       ...\n",
       "2     united yes  We waited in line for almost an h...\n",
       "3     united the we got into the gate at IAH on tim...\n",
       "4     SouthwestAir its cool that my bags take a bit...\n",
       "5     united and don t hope for me having a nicer f...\n",
       "6     united I like delays less than you because I ...\n",
       "7     united  link to current status of flights air...\n",
       "8     SouthwestAir you guys there  Are we on hour  ...\n",
       "9     united I tried   DM it would not go thru    n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#######\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "######## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Stav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "[u'aa', u'abl', u'abov', u'absolut', u'accept']\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = tokenize,  \n",
    "                             preprocessor = None,\n",
    "                             lowercase = True,\n",
    "                             stop_words = 'english',   \n",
    "                             max_features = 1000) \n",
    "\n",
    "data_features = vectorizer.fit_transform(df.text)\n",
    "data_features = data_features.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "\n",
    "word_count_tuple = []\n",
    "for tag, count in zip(vocab, dist):\n",
    "    word_count_tuple.append((tag,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abl</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abov</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolut</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accept</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0       aa  279\n",
       "1      abl  118\n",
       "2     abov   17\n",
       "3  absolut   52\n",
       "4   accept   54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_words_df = pd.DataFrame(word_count_tuple)\n",
    "bag_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9704, 1000) (9704,) (4781, 1000) (4781,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, df.airline_sentiment, test_size = .33)\n",
    "\n",
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame({'importance':forest.feature_importances_, 'vocab':vocab}).sort_values('importance', ascending = False ).set_index('vocab')[0:20].plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting...\n",
      "negative    6083\n",
      "neutral     2025\n",
      "positive    1596\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    2999\n",
      "neutral     1044\n",
      "positive     738\n",
      "Name: airline_sentiment, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.75      0.94      0.83      2999\n",
      "    neutral       0.66      0.27      0.38      1044\n",
      "   positive       0.71      0.58      0.64       738\n",
      "\n",
      "avg / total       0.72      0.74      0.70      4781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"gradient boosting...\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "GBC = GradientBoostingClassifier(loss = 'deviance', learning_rate=.1) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "GBC = GBC.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = GBC.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print cls_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression...\n",
      "negative    6083\n",
      "neutral     2025\n",
      "positive    1596\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    2999\n",
      "neutral     1044\n",
      "positive     738\n",
      "Name: airline_sentiment, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.90      0.86      2999\n",
      "    neutral       0.63      0.52      0.57      1044\n",
      "   positive       0.72      0.65      0.68       738\n",
      "\n",
      "avg / total       0.77      0.78      0.77      4781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"logistic regression...\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "logreg = LogisticRegression(penalty='l2')\n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "logreg = logreg.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print cls_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian nb...\n",
      "negative    6083\n",
      "neutral     2025\n",
      "positive    1596\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    2999\n",
      "neutral     1044\n",
      "positive     738\n",
      "Name: airline_sentiment, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.75      0.94      0.83      2999\n",
      "    neutral       0.66      0.27      0.38      1044\n",
      "   positive       0.71      0.58      0.64       738\n",
      "\n",
      "avg / total       0.72      0.74      0.70      4781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"gaussian nb...\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "GNB = GaussianNB() \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "GNB = GNB.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = GBC.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print cls_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03069438,  0.0590613 ,  0.72789674, ...,  0.56672755,\n",
       "        0.08941444,  0.06930564])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.predict_proba(X_test)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest...\n",
      "negative    6083\n",
      "neutral     2025\n",
      "positive    1596\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    2999\n",
      "neutral     1044\n",
      "positive     738\n",
      "Name: airline_sentiment, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.79      0.93      0.85      2999\n",
      "    neutral       0.64      0.43      0.52      1044\n",
      "   positive       0.74      0.53      0.62       738\n",
      "\n",
      "avg / total       0.75      0.76      0.74      4781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time \n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [ 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"n_jobs\":[-1]}\n",
    "\n",
    "# run grid search\n",
    "# run randomized search\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "forest = GridSearchCV(clf, param_grid=param_grid)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "#forest = RandomForestClassifier(n_estimators = 500, criterion='gini', n_jobs=-1) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = forest.best_estimator_.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print cls_rep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
