{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"./database.sqlite\")\n",
    "df = pd.read_sql_query(\"SELECT * from Tweets\", con)\n",
    "\n",
    "# verify that result of SQL query is stored in the dataframe\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567588278875213824</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue's new CEO seeks the right balance to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-16 23:36:05 -0800</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567590027375702016</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nesi_1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ï¿½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-16 23:43:02 -0800</td>\n",
       "      <td>undecided</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  567588278875213824           neutral                           1.0   \n",
       "1  567590027375702016          negative                           1.0   \n",
       "\n",
       "  negativereason  negativereason_confidence airline airline_sentiment_gold  \\\n",
       "0            NaN                        NaN   Delta                    NaN   \n",
       "1     Can't Tell                     0.6503   Delta                    NaN   \n",
       "\n",
       "          name negativereason_gold  retweet_count  \\\n",
       "0  JetBlueNews                 NaN              0   \n",
       "1    nesi_1992                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @JetBlue's new CEO seeks the right balance to ...         NaN   \n",
       "1  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ï¿½...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-16 23:36:05 -0800            USA                      Sydney  \n",
       "1  2015-02-16 23:43:02 -0800      undecided  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('',np.nan, inplace = True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean text of punctuation, url, stopwords    \n",
    "\n",
    "#stops = set(stopwords.words(\"english\")) \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.encode('utf-8')\n",
    "    text = re.sub('https(.)*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    return text\n",
    "df.text = df.text.apply(lambda val: clean_text(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     JetBlue s new CEO seeks the right balance to ...\n",
       "1     JetBlue is REALLY getting on my nerves       ...\n",
       "2     united yes  We waited in line for almost an h...\n",
       "3     united the we got into the gate at IAH on tim...\n",
       "4     SouthwestAir its cool that my bags take a bit...\n",
       "5     united and don t hope for me having a nicer f...\n",
       "6     united I like delays less than you because I ...\n",
       "7     united  link to current status of flights air...\n",
       "8     SouthwestAir you guys there  Are we on hour  ...\n",
       "9     united I tried   DM it would not go thru    n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#######\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "######## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Stav/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "[u'aa', u'abl', u'absolut', u'accept', u'access']\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = tokenize,  \n",
    "                             preprocessor = None,\n",
    "                             lowercase = True,\n",
    "                             stop_words = 'english',   \n",
    "                             max_features = 1000) \n",
    "\n",
    "data_features = vectorizer.fit_transform(df.text)\n",
    "data_features = data_features.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'aa',\n",
       " u'abl',\n",
       " u'absolut',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accommod',\n",
       " u'account',\n",
       " u'act',\n",
       " u'actual',\n",
       " u'ad',\n",
       " u'add',\n",
       " u'addit',\n",
       " u'address',\n",
       " u'admir',\n",
       " u'advis',\n",
       " u'advisori',\n",
       " u'afternoon',\n",
       " u'agent',\n",
       " u'ago',\n",
       " u'air',\n",
       " u'aircraft',\n",
       " u'airlin',\n",
       " u'airplan',\n",
       " u'airport',\n",
       " u'airway',\n",
       " u'alert',\n",
       " u'allow',\n",
       " u'alon',\n",
       " u'alreadi',\n",
       " u'altern',\n",
       " u'alway',\n",
       " u'amaz',\n",
       " u'america',\n",
       " u'american',\n",
       " u'americanair',\n",
       " u'americanairlin',\n",
       " u'amp',\n",
       " u'angri',\n",
       " u'ani',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'answer',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyth',\n",
       " u'anywher',\n",
       " u'apolog',\n",
       " u'app',\n",
       " u'appar',\n",
       " u'appear',\n",
       " u'appeas',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'area',\n",
       " u'aren',\n",
       " u'arriv',\n",
       " u'asap',\n",
       " u'ask',\n",
       " u'assign',\n",
       " u'assist',\n",
       " u'atl',\n",
       " u'atlanta',\n",
       " u'attempt',\n",
       " u'attend',\n",
       " u'attitud',\n",
       " u'au',\n",
       " u'austin',\n",
       " u'auto',\n",
       " u'autom',\n",
       " u'avail',\n",
       " u'avgeek',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'award',\n",
       " u'away',\n",
       " u'awesom',\n",
       " u'b',\n",
       " u'babi',\n",
       " u'bad',\n",
       " u'badcustomerservic',\n",
       " u'badservic',\n",
       " u'bag',\n",
       " u'baggag',\n",
       " u'bank',\n",
       " u'base',\n",
       " u'basic',\n",
       " u'battl',\n",
       " u'bc',\n",
       " u'beauti',\n",
       " u'becaus',\n",
       " u'becom',\n",
       " u'befor',\n",
       " u'begin',\n",
       " u'believ',\n",
       " u'best',\n",
       " u'better',\n",
       " u'big',\n",
       " u'bin',\n",
       " u'bird',\n",
       " u'birthday',\n",
       " u'bit',\n",
       " u'blame',\n",
       " u'blue',\n",
       " u'bna',\n",
       " u'bo',\n",
       " u'board',\n",
       " u'book',\n",
       " u'boston',\n",
       " u'bother',\n",
       " u'bought',\n",
       " u'break',\n",
       " u'bring',\n",
       " u'broke',\n",
       " u'broken',\n",
       " u'brother',\n",
       " u'bs',\n",
       " u'btw',\n",
       " u'bu',\n",
       " u'buffalo',\n",
       " u'bump',\n",
       " u'busi',\n",
       " u'buy',\n",
       " u'bwi',\n",
       " u'c',\n",
       " u'cabin',\n",
       " u'callback',\n",
       " u'came',\n",
       " u'cancel',\n",
       " u'captain',\n",
       " u'car',\n",
       " u'card',\n",
       " u'care',\n",
       " u'carri',\n",
       " u'carrier',\n",
       " u'case',\n",
       " u'catch',\n",
       " u'cater',\n",
       " u'caus',\n",
       " u'cc',\n",
       " u'center',\n",
       " u'ceo',\n",
       " u'chairman',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'charg',\n",
       " u'charlott',\n",
       " u'cheap',\n",
       " u'check',\n",
       " u'checkin',\n",
       " u'chicago',\n",
       " u'child',\n",
       " u'children',\n",
       " u'choic',\n",
       " u'choos',\n",
       " u'citi',\n",
       " u'claim',\n",
       " u'class',\n",
       " u'clean',\n",
       " u'clear',\n",
       " u'clearli',\n",
       " u'close',\n",
       " u'cloth',\n",
       " u'clt',\n",
       " u'club',\n",
       " u'clue',\n",
       " u'cmh',\n",
       " u'coach',\n",
       " u'code',\n",
       " u'coffe',\n",
       " u'cold',\n",
       " u'columbu',\n",
       " u'com',\n",
       " u'come',\n",
       " u'commerci',\n",
       " u'commun',\n",
       " u'comp',\n",
       " u'compani',\n",
       " u'companion',\n",
       " u'compens',\n",
       " u'complain',\n",
       " u'complaint',\n",
       " u'complet',\n",
       " u'comput',\n",
       " u'concern',\n",
       " u'condit',\n",
       " u'conf',\n",
       " u'confirm',\n",
       " u'confus',\n",
       " u'congrat',\n",
       " u'connect',\n",
       " u'consid',\n",
       " u'consist',\n",
       " u'contact',\n",
       " u'continu',\n",
       " u'control',\n",
       " u'cool',\n",
       " u'corpor',\n",
       " u'correct',\n",
       " u'cost',\n",
       " u'couldn',\n",
       " u'count',\n",
       " u'counter',\n",
       " u'countri',\n",
       " u'coupl',\n",
       " u'cours',\n",
       " u'cover',\n",
       " u'crash',\n",
       " u'crazi',\n",
       " u'credit',\n",
       " u'crew',\n",
       " u'cross',\n",
       " u'cs',\n",
       " u'current',\n",
       " u'cust',\n",
       " u'custom',\n",
       " u'customerservic',\n",
       " u'cut',\n",
       " u'd',\n",
       " u'dal',\n",
       " u'dalla',\n",
       " u'damag',\n",
       " u'damn',\n",
       " u'date',\n",
       " u'daughter',\n",
       " u'day',\n",
       " u'dc',\n",
       " u'dca',\n",
       " u'deal',\n",
       " u'decid',\n",
       " u'definit',\n",
       " u'delay',\n",
       " u'deliv',\n",
       " u'deliveri',\n",
       " u'delta',\n",
       " u'den',\n",
       " u'deni',\n",
       " u'denver',\n",
       " u'depart',\n",
       " u'departur',\n",
       " u'deplan',\n",
       " u'dept',\n",
       " u'deserv',\n",
       " u'desk',\n",
       " u'despit',\n",
       " u'destin',\n",
       " u'destinationdragon',\n",
       " u'dfw',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'die',\n",
       " u'diego',\n",
       " u'differ',\n",
       " u'direct',\n",
       " u'disappoint',\n",
       " u'disconnect',\n",
       " u'discount',\n",
       " u'disgust',\n",
       " u'dividend',\n",
       " u'dm',\n",
       " u'doe',\n",
       " u'doesn',\n",
       " u'dollar',\n",
       " u'domest',\n",
       " u'don',\n",
       " u'dont',\n",
       " u'door',\n",
       " u'dragon',\n",
       " u'drink',\n",
       " u'drive',\n",
       " u'drop',\n",
       " u'dull',\n",
       " u'dure',\n",
       " u'e',\n",
       " u'earli',\n",
       " u'earlier',\n",
       " u'earn',\n",
       " u'easi',\n",
       " u'effort',\n",
       " u'els',\n",
       " u'email',\n",
       " u'emerg',\n",
       " u'employe',\n",
       " u'empti',\n",
       " u'end',\n",
       " u'engin',\n",
       " u'enjoy',\n",
       " u'enter',\n",
       " u'entertain',\n",
       " u'entir',\n",
       " u'equip',\n",
       " u'error',\n",
       " u'especi',\n",
       " u'estim',\n",
       " u'event',\n",
       " u'everi',\n",
       " u'everyon',\n",
       " u'everyth',\n",
       " u'ewr',\n",
       " u'exactli',\n",
       " u'excel',\n",
       " u'excit',\n",
       " u'excus',\n",
       " u'exist',\n",
       " u'exit',\n",
       " u'expect',\n",
       " u'expens',\n",
       " u'experi',\n",
       " u'experienc',\n",
       " u'expir',\n",
       " u'explain',\n",
       " u'explan',\n",
       " u'extend',\n",
       " u'extra',\n",
       " u'extrem',\n",
       " u'f',\n",
       " u'fa',\n",
       " u'face',\n",
       " u'fact',\n",
       " u'fail',\n",
       " u'failur',\n",
       " u'fair',\n",
       " u'fall',\n",
       " u'famili',\n",
       " u'fan',\n",
       " u'fantast',\n",
       " u'far',\n",
       " u'fare',\n",
       " u'fast',\n",
       " u'fault',\n",
       " u'favorit',\n",
       " u'feb',\n",
       " u'fee',\n",
       " u'feedback',\n",
       " u'feel',\n",
       " u'figur',\n",
       " u'file',\n",
       " u'final',\n",
       " u'fine',\n",
       " u'finger',\n",
       " u'fit',\n",
       " u'fix',\n",
       " u'fl',\n",
       " u'fleek',\n",
       " u'fleet',\n",
       " u'flew',\n",
       " u'fli',\n",
       " u'flight',\n",
       " u'flightat',\n",
       " u'flightd',\n",
       " u'flightl',\n",
       " u'flightlat',\n",
       " u'flightr',\n",
       " u'fll',\n",
       " u'florida',\n",
       " u'flown',\n",
       " u'flt',\n",
       " u'flyer',\n",
       " u'folk',\n",
       " u'follow',\n",
       " u'food',\n",
       " u'forc',\n",
       " u'forev',\n",
       " u'forgot',\n",
       " u'form',\n",
       " u'forward',\n",
       " u'free',\n",
       " u'freez',\n",
       " u'frequent',\n",
       " u'friday',\n",
       " u'friend',\n",
       " u'friendli',\n",
       " u'frustrat',\n",
       " u'fuck',\n",
       " u'fuel',\n",
       " u'fun',\n",
       " u'fund',\n",
       " u'funer',\n",
       " u'funni',\n",
       " u'futur',\n",
       " u'fyi',\n",
       " u'g',\n",
       " u'game',\n",
       " u'gate',\n",
       " u'gave',\n",
       " u'gener',\n",
       " u'given',\n",
       " u'glad',\n",
       " u'god',\n",
       " u'goe',\n",
       " u'gold',\n",
       " u'gon',\n",
       " u'gone',\n",
       " u'good',\n",
       " u'got',\n",
       " u'gotten',\n",
       " u'great',\n",
       " u'ground',\n",
       " u'group',\n",
       " u'gt',\n",
       " u'guess',\n",
       " u'guy',\n",
       " u'h',\n",
       " u'ha',\n",
       " u'haha',\n",
       " u'half',\n",
       " u'hand',\n",
       " u'handl',\n",
       " u'hang',\n",
       " u'happen',\n",
       " u'happi',\n",
       " u'hard',\n",
       " u'hasn',\n",
       " u'hate',\n",
       " u'haven',\n",
       " u'head',\n",
       " u'hear',\n",
       " u'heard',\n",
       " u'held',\n",
       " u'hell',\n",
       " u'hello',\n",
       " u'help',\n",
       " u'hey',\n",
       " u'hi',\n",
       " u'high',\n",
       " u'hire',\n",
       " u'hit',\n",
       " u'hold',\n",
       " u'home',\n",
       " u'honor',\n",
       " u'hope',\n",
       " u'horribl',\n",
       " u'hotel',\n",
       " u'hour',\n",
       " u'houston',\n",
       " u'howev',\n",
       " u'hr',\n",
       " u'http',\n",
       " u'huge',\n",
       " u'human',\n",
       " u'hung',\n",
       " u'husband',\n",
       " u'iad',\n",
       " u'iah',\n",
       " u'ice',\n",
       " u'id',\n",
       " u'idea',\n",
       " u'ignor',\n",
       " u'im',\n",
       " u'imagin',\n",
       " u'imaginedragon',\n",
       " u'import',\n",
       " u'imposs',\n",
       " u'impress',\n",
       " u'improv',\n",
       " u'includ',\n",
       " u'incompet',\n",
       " u'inconveni',\n",
       " u'incred',\n",
       " u'infant',\n",
       " u'inflight',\n",
       " u'info',\n",
       " u'inform',\n",
       " u'insid',\n",
       " u'instead',\n",
       " u'intern',\n",
       " u'internet',\n",
       " u'intl',\n",
       " u'iphon',\n",
       " u'isn',\n",
       " u'issu',\n",
       " u'item',\n",
       " u'itinerari',\n",
       " u'j',\n",
       " u'jb',\n",
       " u'jet',\n",
       " u'jetblu',\n",
       " u'jfk',\n",
       " u'job',\n",
       " u'joke',\n",
       " u'just',\n",
       " u'k',\n",
       " u'kept',\n",
       " u'kid',\n",
       " u'kill',\n",
       " u'kind',\n",
       " u'knew',\n",
       " u'know',\n",
       " u'kudo',\n",
       " u'l',\n",
       " u'la',\n",
       " u'lack',\n",
       " u'ladi',\n",
       " u'land',\n",
       " u'late',\n",
       " u'lax',\n",
       " u'layov',\n",
       " u'learn',\n",
       " u'leav',\n",
       " u'left',\n",
       " u'leg',\n",
       " u'let',\n",
       " u'letter',\n",
       " u'level',\n",
       " u'lga',\n",
       " u'lie',\n",
       " u'life',\n",
       " u'like',\n",
       " u'limit',\n",
       " u'line',\n",
       " u'link',\n",
       " u'list',\n",
       " u'listen',\n",
       " u'liter',\n",
       " u'littl',\n",
       " u'live',\n",
       " u'll',\n",
       " u'load',\n",
       " u'locat',\n",
       " u'log',\n",
       " u'lol',\n",
       " u'long',\n",
       " u'longer',\n",
       " u'look',\n",
       " u'lose',\n",
       " u'lost',\n",
       " u'lot',\n",
       " u'loung',\n",
       " u'love',\n",
       " u'loyal',\n",
       " u'lt',\n",
       " u'luck',\n",
       " u'luggag',\n",
       " u'luv',\n",
       " u'm',\n",
       " u'mad',\n",
       " u'mail',\n",
       " u'main',\n",
       " u'mainten',\n",
       " u'major',\n",
       " u'make',\n",
       " u'man',\n",
       " u'manag',\n",
       " u'mani',\n",
       " u'march',\n",
       " u'match',\n",
       " u'matter',\n",
       " u'mayb',\n",
       " u'mco',\n",
       " u'meal',\n",
       " u'mean',\n",
       " u'mechan',\n",
       " u'media',\n",
       " u'meet',\n",
       " u'member',\n",
       " u'mention',\n",
       " u'merg',\n",
       " u'merger',\n",
       " u'mess',\n",
       " u'messag',\n",
       " u'mexico',\n",
       " u'mia',\n",
       " u'miami',\n",
       " u'middl',\n",
       " u'midnight',\n",
       " u'mile',\n",
       " u'mileag',\n",
       " u'min',\n",
       " u'mind',\n",
       " u'minut',\n",
       " u'miss',\n",
       " u'mistak',\n",
       " u'mobil',\n",
       " u'mom',\n",
       " u'monday',\n",
       " u'money',\n",
       " u'month',\n",
       " u'morn',\n",
       " u'multipl',\n",
       " u'music',\n",
       " u'n',\n",
       " u'na',\n",
       " u'nashvil',\n",
       " u'nc',\n",
       " u'nd',\n",
       " u'need',\n",
       " u'neveragain',\n",
       " u'new',\n",
       " u'newark',\n",
       " u'news',\n",
       " u'nice',\n",
       " u'night',\n",
       " u'nightmar',\n",
       " u'non',\n",
       " u'nonstop',\n",
       " u'nope',\n",
       " u'note',\n",
       " u'noth',\n",
       " u'notic',\n",
       " u'notif',\n",
       " u'notifi',\n",
       " u'number',\n",
       " u'ny',\n",
       " u'nyc',\n",
       " u'o',\n",
       " u'offer',\n",
       " u'offic',\n",
       " u'offici',\n",
       " u'oh',\n",
       " u'ok',\n",
       " u'okay',\n",
       " u'old',\n",
       " u'onboard',\n",
       " u'onc',\n",
       " u'onli',\n",
       " u'onlin',\n",
       " u'open',\n",
       " u'oper',\n",
       " u'option',\n",
       " u'ord',\n",
       " u'order',\n",
       " u'origin',\n",
       " u'orlando',\n",
       " u'oscar',\n",
       " u'outsid',\n",
       " u'overbook',\n",
       " u'overhead',\n",
       " u'overnight',\n",
       " u'p',\n",
       " u'page',\n",
       " u'paid',\n",
       " u'parti',\n",
       " u'partner',\n",
       " u'pass',\n",
       " u'passbook',\n",
       " u'passeng',\n",
       " u'past',\n",
       " u'pathet',\n",
       " u'patient',\n",
       " u'pay',\n",
       " u'pdx',\n",
       " u'peopl',\n",
       " u'person',\n",
       " u'philadelphia',\n",
       " u'philli',\n",
       " u'phl',\n",
       " u'phlairport',\n",
       " u'phoenix',\n",
       " u'phone',\n",
       " u'photo',\n",
       " u'phx',\n",
       " u'pick',\n",
       " u'pilot',\n",
       " u'pl',\n",
       " u'place',\n",
       " u'plan',\n",
       " u'plane',\n",
       " u'platinum',\n",
       " u'play',\n",
       " u'pleas',\n",
       " u'plu',\n",
       " u'plz',\n",
       " u'pm',\n",
       " u'point',\n",
       " u'polici',\n",
       " u'poor',\n",
       " u'posit',\n",
       " u'possibl',\n",
       " u'post',\n",
       " u'power',\n",
       " u'ppl',\n",
       " u'pre',\n",
       " u'prefer',\n",
       " u'premier',\n",
       " u'pretti',\n",
       " u'price',\n",
       " u'print',\n",
       " u'prioriti',\n",
       " u'probabl',\n",
       " u'problem',\n",
       " u'process',\n",
       " u'profit',\n",
       " u'program',\n",
       " u'promis',\n",
       " u'prompt',\n",
       " u'provid',\n",
       " u'pull',\n",
       " u'purchas',\n",
       " u'push',\n",
       " u'q',\n",
       " u'question',\n",
       " u'quick',\n",
       " u'r',\n",
       " u'rais',\n",
       " u'rate',\n",
       " u'rd',\n",
       " u'rdu',\n",
       " u'reach',\n",
       " u'read',\n",
       " u'readi',\n",
       " u'real',\n",
       " u'realiz',\n",
       " u'realli',\n",
       " u'reason',\n",
       " u'rebook',\n",
       " u'receipt',\n",
       " u'receiv',\n",
       " u'recent',\n",
       " u'record',\n",
       " u'redeem',\n",
       " u'reflight',\n",
       " u'refund',\n",
       " u'refus',\n",
       " u'regard',\n",
       " u'reimburs',\n",
       " u'relat',\n",
       " u'rememb',\n",
       " u'remind',\n",
       " u'rental',\n",
       " u'rep',\n",
       " u'replac',\n",
       " u'repli',\n",
       " u'report',\n",
       " u'repres',\n",
       " u'request',\n",
       " u'requir',\n",
       " u'rerout',\n",
       " u'reschedul',\n",
       " u'reserv',\n",
       " u'resolut',\n",
       " u'resolv',\n",
       " u'respond',\n",
       " u'respons',\n",
       " u'result',\n",
       " u'return',\n",
       " u'reward',\n",
       " u'ride',\n",
       " u'ridicul',\n",
       " u'right',\n",
       " u'rock',\n",
       " u'room',\n",
       " u'round',\n",
       " u'rout',\n",
       " u'row',\n",
       " u'rt',\n",
       " u'rude',\n",
       " u'ruin',\n",
       " u'rule',\n",
       " u'run',\n",
       " u'runway',\n",
       " u's',\n",
       " u'sad',\n",
       " u'safe',\n",
       " u'safeti',\n",
       " u'said',\n",
       " u'san',\n",
       " u'sat',\n",
       " u'saturday',\n",
       " u'save',\n",
       " u'saw',\n",
       " u'say',\n",
       " u'schedul',\n",
       " u'screen',\n",
       " u'screw',\n",
       " u'sea',\n",
       " u'seat',\n",
       " u'seattl',\n",
       " u'second',\n",
       " u'secur',\n",
       " u'seen',\n",
       " u'select',\n",
       " u'sell',\n",
       " u'send',\n",
       " u'sens',\n",
       " u'sent',\n",
       " u'seriou',\n",
       " u'serv',\n",
       " u'servic',\n",
       " u'set',\n",
       " u'sever',\n",
       " u'sfo',\n",
       " u'shame',\n",
       " u'share',\n",
       " u'shit',\n",
       " u'short',\n",
       " u'shot',\n",
       " u'shouldn',\n",
       " u'sick',\n",
       " u'sign',\n",
       " u'sinc',\n",
       " u'singl',\n",
       " u'sister',\n",
       " u'sit',\n",
       " u'site',\n",
       " u'situat',\n",
       " u'sky',\n",
       " u'sleep',\n",
       " u'slow',\n",
       " u'small',\n",
       " u'smh',\n",
       " u'snack',\n",
       " u'snow',\n",
       " u'social',\n",
       " u'sold',\n",
       " u'solut',\n",
       " u'someon',\n",
       " u'someth',\n",
       " u'son',\n",
       " u'soon',\n",
       " u'sorri',\n",
       " u'sort',\n",
       " u'sound',\n",
       " u'south',\n",
       " u'southwest',\n",
       " u'southwestair',\n",
       " u'space',\n",
       " u'speak',\n",
       " u'special',\n",
       " u'specif',\n",
       " u'spend',\n",
       " u'spent',\n",
       " u'spoke',\n",
       " u'st',\n",
       " u'staff',\n",
       " u'stand',\n",
       " u'standbi',\n",
       " u'start',\n",
       " u'state',\n",
       " u'statu',\n",
       " u'stay',\n",
       " u'step',\n",
       " u'stewardess',\n",
       " u'stop',\n",
       " u'stori',\n",
       " u'storm',\n",
       " u'strand',\n",
       " u'street',\n",
       " u'stress',\n",
       " u'stuck',\n",
       " u'stuff',\n",
       " u'submit',\n",
       " u'suck',\n",
       " u'suggest',\n",
       " u'suitcas',\n",
       " u'sunday',\n",
       " u'super',\n",
       " u'supervisor',\n",
       " u'support',\n",
       " u'suppos',\n",
       " u'sure',\n",
       " u'surpris',\n",
       " u'svc',\n",
       " u'sw',\n",
       " u'swa',\n",
       " u'switch',\n",
       " u't',\n",
       " u'ta',\n",
       " u'tag',\n",
       " u'taken',\n",
       " u'takeoff',\n",
       " u'talk',\n",
       " u'tarmac',\n",
       " u'taxi',\n",
       " u'team',\n",
       " u'tell',\n",
       " u'termin',\n",
       " u'terribl',\n",
       " u'text',\n",
       " u'th',\n",
       " u'thank',\n",
       " u'thi',\n",
       " u'thing',\n",
       " u'think',\n",
       " u'tho',\n",
       " u'thought',\n",
       " u'thx',\n",
       " u'ticket',\n",
       " u'till',\n",
       " u'time',\n",
       " u'tire',\n",
       " u'tix',\n",
       " u'tmrw',\n",
       " u'today',\n",
       " u'togeth',\n",
       " u'told',\n",
       " u'tomorrow',\n",
       " u'tonight',\n",
       " u'took',\n",
       " u'total',\n",
       " u'touch',\n",
       " u'track',\n",
       " u'train',\n",
       " u'transfer',\n",
       " u'travel',\n",
       " u'treat',\n",
       " u'tri',\n",
       " u'trip',\n",
       " u'troubl',\n",
       " u'true',\n",
       " u'trueblu',\n",
       " u'trust',\n",
       " u'tsa',\n",
       " u'tuesday',\n",
       " u'turn',\n",
       " u'tv',\n",
       " u'tweet',\n",
       " u'twice',\n",
       " u'twitter',\n",
       " u'u',\n",
       " u'ua',\n",
       " u'ugh',\n",
       " u'uk',\n",
       " u'unabl',\n",
       " u'unaccept',\n",
       " u'unbeliev',\n",
       " u'understand',\n",
       " u'unfortun',\n",
       " u'unhappi',\n",
       " u'unhelp',\n",
       " u'unit',\n",
       " u'unitedairlin',\n",
       " u'updat',\n",
       " u'upgrad',\n",
       " u'upset',\n",
       " u'ur',\n",
       " u'usa',\n",
       " u'usair',\n",
       " u'usairway',\n",
       " u'usairwaysfail',\n",
       " u'use',\n",
       " u'useless',\n",
       " u'usual',\n",
       " u'v',\n",
       " u'vacat',\n",
       " u've',\n",
       " u'vega',\n",
       " u'veri',\n",
       " u'video',\n",
       " u'view',\n",
       " u'virgin',\n",
       " u'virginamerica',\n",
       " u'visit',\n",
       " u'volum',\n",
       " u'voucher',\n",
       " u'w',\n",
       " u'wa',\n",
       " u'wait',\n",
       " u'waiv',\n",
       " u'walk',\n",
       " u'wall',\n",
       " u'want',\n",
       " u'warm',\n",
       " u'wasn',\n",
       " u'wast',\n",
       " u'watch',\n",
       " u'water',\n",
       " u'way',\n",
       " u'weather',\n",
       " u'web',\n",
       " u'websit',\n",
       " u'wed',\n",
       " u'wednesday',\n",
       " u'week',\n",
       " u'weekend',\n",
       " u'welcom',\n",
       " u'went',\n",
       " u'weren',\n",
       " u'whi',\n",
       " u'wife',\n",
       " u'wifi',\n",
       " u'win',\n",
       " u'window',\n",
       " u'winter',\n",
       " u'wish',\n",
       " u'won',\n",
       " u'wonder',\n",
       " u'word',\n",
       " u'work',\n",
       " u'world',\n",
       " u'worri',\n",
       " u'wors',\n",
       " u'worst',\n",
       " u'worth',\n",
       " u'wouldn',\n",
       " u'wow',\n",
       " u'write',\n",
       " u'wrong',\n",
       " u'wtf',\n",
       " u'x',\n",
       " u'y',\n",
       " u'yall',\n",
       " u'ye',\n",
       " u'yeah',\n",
       " u'year',\n",
       " u'yep',\n",
       " u'yesterday',\n",
       " u'yo',\n",
       " u'yr',\n",
       " u'z',\n",
       " u'zero']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "\n",
    "word_count_tuple = []\n",
    "for tag, count in zip(vocab, dist):\n",
    "    word_count_tuple.append((tag,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abl</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolut</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accept</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>access</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0       aa  279\n",
       "1      abl  118\n",
       "2  absolut   52\n",
       "3   accept   54\n",
       "4   access   41"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_words_df = pd.DataFrame(word_count_tuple)\n",
    "bag_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14485"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9704, 1000) (9704,) (4781, 1000) (4781,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, df.airline_sentiment, test_size = .33)\n",
    "\n",
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "negative    6083\n",
      "neutral     2065\n",
      "positive    1556\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    2999\n",
      "neutral     1004\n",
      "positive     778\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100, criterion='gini', n_jobs=-1) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.81      0.89      0.85      2999\n",
      "    neutral       0.57      0.46      0.51      1004\n",
      "   positive       0.70      0.60      0.65       778\n",
      "\n",
      "avg / total       0.74      0.75      0.74      4781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print cls_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    6082\n",
      "neutral     2065\n",
      "positive    1557\n",
      "Name: airline_sentiment, dtype: int64\n",
      "negative    3000\n",
      "neutral     1004\n",
      "positive     777\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print y_train.value_counts()\n",
    "print y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a756c52136b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize a Random Forest classifier with 100 trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit the forest to the training set, using the bag of words as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_jobs'"
     ]
    }
   ],
   "source": [
    "print \"gradient boosting...\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = GradientBoostingClassifier(n_estimators = 100, criterion='gini', n_jobs=-1) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "print y_train.value_counts()\n",
    "print y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
